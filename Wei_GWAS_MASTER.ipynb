{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fuwei\\Desktop\\GWASReview\\GWASReview-master\\data\\Catalogue\\Raw\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.abspath(os.path.join('__file__',\n",
    "                                    '../..',\n",
    "                                    'data',\n",
    "                                    'Catalogue',\n",
    "                                    'Raw'))\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.15.4)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.21.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.24.1)\n",
      "Collecting requests_ftp\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from requests_ftp) (2.21.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->requests_ftp) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->requests_ftp) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->requests_ftp) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->requests_ftp) (2.8)\n",
      "Installing collected packages: requests-ftp\n",
      "Successfully installed requests-ftp-0.3.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy \n",
    "!{sys.executable} -m pip install requests\n",
    "!{sys.executable} -m pip install requests_ftp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the raw GWAS data from the ebi website. \n",
    "Here, the function download_cat need to be revoked, which is located in **Module: loaddata.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests_ftp\n",
    "\n",
    "def download_cat(path, ebi_download):\n",
    "    \"\"\" download the data from the ebi main site and ftp\"\"\"\n",
    "    r = requests.get(ebi_download + 'studies_alternative')\n",
    "    with open(os.path.join(path, 'Cat_Stud.tsv'), 'wb') as tsvfile:\n",
    "        tsvfile.write(r.content)\n",
    "    r = requests.get(ebi_download + 'ancestry')\n",
    "    with open(os.path.join(path, 'Cat_Anc.tsv'), 'wb') as tsvfile:\n",
    "        tsvfile.write(r.content)H\n",
    "    r = requests.get(ebi_download + 'full')\n",
    "    with open(os.path.join(path, 'Cat_Full.tsv'), 'wb') as tsvfile:\n",
    "        tsvfile.write(r.content)\n",
    "    requests_ftp.monkeypatch_session()\n",
    "    s = requests.Session()\n",
    "    ftpsite = 'ftp://ftp.ebi.ac.uk/'\n",
    "    subdom = '/pub/databases/gwas/releases/latest/'\n",
    "    file = 'gwas-efo-trait-mappings.tsv'\n",
    "    r = s.get(ftpsite+subdom+file)\n",
    "    with open(os.path.join(path, 'Cat_Map.tsv'), 'wb') as tsvfile:\n",
    "        tsvfile.write(r.content)\n",
    "\n",
    "ebi_download = 'https://www.ebi.ac.uk/gwas/api/search/downloads/'\n",
    "download_cat(output_path, ebi_download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets link the PUBMEDID variable to the PUBMED AP.\n",
    "This will get a series of datasets from that using the support functions written in PubMed.py. Note: collective corresponds mostly consortia and study groups.\n",
    "* function load_gwas_cat() in **module: ** need to be revoked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (0.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2018.7)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.15.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip uninstall numpy\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install biopython\n",
    "!{sys.executable} -m pip install Bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Bio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-527a4cab0d2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mBio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEntrez\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_gwas_cat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Bio'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "from Bio import Entrez\n",
    "\n",
    "def load_gwas_cat():\n",
    "    \"\"\"A function which cleans and loads all the main GWAS Catalog files into\n",
    "    the notebook workspace. It renames a couple of fields, and creates\n",
    "    one groupedby.sum for return\n",
    "    \"\"\"\n",
    "    Cat_Stud = pd.read_csv(os.path.abspath(\n",
    "                           os.path.join('__file__',\n",
    "                                        '../..',\n",
    "                                        'data',\n",
    "                                        'Catalogue',\n",
    "                                        'Raw',\n",
    "                                        'Cat_Stud.tsv')),\n",
    "                           header=0, sep='\\t', encoding='utf-8',\n",
    "                           index_col=False)\n",
    "    Cat_Stud.fillna('N/A', inplace=True)\n",
    "    Cat_Anc = pd.read_csv(os.path.abspath(\n",
    "                          os.path.join('__file__', '../..',\n",
    "                                       'data',\n",
    "                                       'Catalogue',\n",
    "                                       'Raw',\n",
    "                                       'Cat_Anc.tsv')),\n",
    "                          header=0, sep='\\t', encoding='utf-8',\n",
    "                          index_col=False)\n",
    "    Cat_Anc.rename(columns={'BROAD ANCESTRAL CATEGORY': 'BROAD ANCESTRAL',\n",
    "                            'NUMBER OF INDIVDUALS': 'N'}, inplace=True)\n",
    "    Cat_Anc = Cat_Anc[~Cat_Anc['BROAD ANCESTRAL'].isnull()]\n",
    "    Cat_Anc.columns = Cat_Anc.columns.str.replace('ACCCESSION', 'ACCESSION')\n",
    "    Cat_Anc_byN = Cat_Anc[['STUDY ACCESSION', 'N',\n",
    "                           'DATE']].groupby(by='STUDY ACCESSION').sum()\n",
    "    Cat_Anc_byN = Cat_Anc_byN.reset_index()\n",
    "    Cat_Anc_byN = pd.merge(Cat_Anc_byN, Cat_Stud[[\n",
    "        'STUDY ACCESSION', 'DATE']], how='left', on='STUDY ACCESSION')\n",
    "    cleaner_broad = pd.read_csv(os.path.abspath(\n",
    "        os.path.join('__file__',\n",
    "                     '../..',\n",
    "                     'data',\n",
    "                     'Support',\n",
    "                     'dict_replacer_broad.tsv')),\n",
    "        sep='\\t', header=0, index_col=False)\n",
    "    Cat_Anc = pd.merge(Cat_Anc, cleaner_broad, how='left',\n",
    "                       on='BROAD ANCESTRAL')\n",
    "    Cat_Anc['Dates'] = [pd.to_datetime(d) for d in Cat_Anc['DATE']]\n",
    "    Cat_Anc['N'] = pd.to_numeric(Cat_Anc['N'], errors='coerce')\n",
    "    Cat_Anc = Cat_Anc[Cat_Anc['N'].notnull()]\n",
    "    Cat_Anc['N'] = Cat_Anc['N'].astype(int)\n",
    "    Cat_Anc = Cat_Anc.sort_values(by='Dates')\n",
    "    Cat_Anc['Broader']\n",
    "    Cat_Anc['Broader'] = Cat_Anc['Broader'].str.replace(\n",
    "        'African American or Afro-Caribbean', 'African Am./Caribbean')\n",
    "    Cat_Anc['Broader'] = Cat_Anc['Broader'].str.replace(\n",
    "        'Hispanic or Latin American', 'Hispanic/Latin American')\n",
    "    Cat_Full = pd.read_csv(os.path.abspath(os.path.join('__file__',\n",
    "                                                        '../..',\n",
    "                                                        'data',\n",
    "                                                        'Catalogue',\n",
    "                                                        'Raw',\n",
    "                                                        'Cat_Full.tsv')),\n",
    "                           header=0, sep='\\t', encoding='utf-8',\n",
    "                           index_col=False, low_memory=False)\n",
    "\n",
    "    Cat_Anc.to_csv(os.path.abspath(\n",
    "        os.path.join('__file__',\n",
    "                     '../..',\n",
    "                     'data',\n",
    "                     'Catalogue',\n",
    "                     'Synthetic',\n",
    "                     'Cat_Anc_withBroader.tsv')),\n",
    "                   sep='\\t', index=False)\n",
    "    return Cat_Stud, Cat_Anc, Cat_Anc_byN, Cat_Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Entrez' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-387c557cdc1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mCat_Studies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCat_Ancestry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCat_Ancestry_groupedbyN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCat_Full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_gwas_cat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mid_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCat_Studies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PUBMEDID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mEntrez\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memail\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'your@email.com'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpapers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEntrez\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEntrez\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mefetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pubmed'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mretmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'xml'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbuild_collective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpapers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Entrez' is not defined"
     ]
    }
   ],
   "source": [
    "Cat_Studies, Cat_Ancestry, Cat_Ancestry_groupedbyN, Cat_Full = load_gwas_cat()\n",
    "id_list = set(Cat_Studies['PUBMEDID'].astype(str).tolist())\n",
    "Entrez.email = 'your@email.com'\n",
    "papers = Entrez.read(Entrez.efetch(db='pubmed',retmode='xml', id=','.join(id_list)))\n",
    "build_collective(papers)\n",
    "build_author(papers)\n",
    "build_funder(papers)\n",
    "build_abstract(papers)\n",
    "build_citation(id_list,Entrez.email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
